#!/usr/bin/env python3
"""
Generate Python types from shared OpenAPI schemas.
This ensures all services use the same type definitions.
"""

import yaml
from pathlib import Path
from typing import Dict, Any, List, Set


def main():
    """Auto-discover and generate Python types from all YAML files."""
    script_dir = Path(__file__).parent
    shared_dir = script_dir.parent
    types_dir = shared_dir / "types"
    output_dir = shared_dir / "generated" / "python"
    
    # Ensure output directory exists
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Track all generated modules for __init__.py
    generated_modules = []
    all_exports = []
    
    # Auto-discover and process all YAML files
    for yaml_file in sorted(types_dir.glob("*.yaml")):
        module_name = yaml_file.stem.replace("-", "_")
        output_file = output_dir / f"{module_name}.py"
        
        print(f"Processing {yaml_file.name}...")
        exports = generate_from_yaml(yaml_file, output_file)
        
        if exports:
            generated_modules.append((module_name, exports))
            all_exports.extend(exports)
            print(f"  Generated {output_file.name} with exports: {', '.join(exports)}")
    
    # Update __init__.py with all generated types
    update_init_file(output_dir, generated_modules, all_exports)
    print(f"\nGenerated {len(generated_modules)} modules with {len(all_exports)} total exports")


def generate_from_yaml(yaml_file: Path, output_file: Path) -> List[str]:
    """Generate Python code from a single YAML file."""
    with open(yaml_file, "r") as f:
        spec = yaml.safe_load(f)
    
    if not spec or "components" not in spec or "schemas" not in spec["components"]:
        return []
    
    schemas = spec["components"]["schemas"]
    exports = []
    
    # Generate file header
    code = generate_header(yaml_file)
    
    # Determine what imports we need
    imports = determine_imports(schemas)
    
    # Find cross-file dependencies
    cross_file_deps = find_cross_file_dependencies(schemas)
    
    code += generate_imports(imports, cross_file_deps)
    
    # Generate each schema
    for name, schema in schemas.items():
        # Skip meta-schemas or helper schemas
        if name.startswith("x-") or name == "TerminalStates":
            continue
            
        if "enum" in schema:
            code += generate_enum(name, schema)
            exports.append(name)
        elif schema.get("type") == "object":
            code += generate_model(name, schema, schemas)
            exports.append(name)
        # Skip array types and other non-object schemas
    
    # Add channel constants if this is the events file
    if yaml_file.stem == "event-contracts":
        code += generate_event_channels()
        exports.append("EventChannels")
    
    # Write the generated code
    output_file.write_text(code)
    
    return exports


def generate_header(yaml_file: Path) -> str:
    """Generate file header with metadata."""
    return f'''"""
Generated from {yaml_file.name}
DO NOT EDIT THIS FILE DIRECTLY - Edit the source YAML instead

Generated by: shared/scripts/generate-python-types.py
Source: shared/types/{yaml_file.name}
"""

'''


def determine_imports(schemas: Dict[str, Any]) -> Set[str]:
    """Determine what imports are needed based on schemas."""
    imports = set()
    
    for schema in schemas.values():
        # Check if we need datetime
        if has_datetime_fields(schema):
            imports.add("datetime")
        
        # Check if we need typing imports
        if has_optional_fields(schema) or has_dict_fields(schema) or has_list_fields(schema):
            imports.add("typing")
        
        # Check if we need pydantic
        if schema.get("type") == "object" and "enum" not in schema:
            imports.add("pydantic")
        
        # Check if we need enum
        if "enum" in schema:
            imports.add("enum")
    
    return imports


def find_cross_file_dependencies(schemas: Dict[str, Any]) -> Set[str]:
    """Find dependencies on types from other files."""
    deps = set()
    
    def check_schema(schema: Any):
        if isinstance(schema, dict):
            if "$ref" in schema:
                # Parse refs like "./evaluation-status.yaml#/components/schemas/EvaluationStatus"
                ref = schema["$ref"]
                if ref.startswith("./") and "#" in ref:
                    file_part, path_part = ref.split("#")
                    type_name = path_part.split("/")[-1]
                    module_name = file_part[2:].replace(".yaml", "").replace("-", "_")
                    deps.add(f"{module_name}:{type_name}")
            
            for value in schema.values():
                check_schema(value)
        elif isinstance(schema, list):
            for item in schema:
                check_schema(item)
    
    for schema in schemas.values():
        check_schema(schema)
    
    return deps


def generate_imports(imports: Set[str], cross_file_deps: Set[str]) -> str:
    """Generate import statements."""
    code = ""
    
    if "datetime" in imports:
        code += "from datetime import datetime\n"
    
    if "typing" in imports:
        typing_imports = []
        # Always include these if typing is needed
        typing_imports.extend(["Optional", "Dict", "Any", "List"])
        code += f"from typing import {', '.join(typing_imports)}\n"
    
    if "pydantic" in imports:
        code += "from pydantic import BaseModel, Field\n"
    
    if "enum" in imports:
        code += "from enum import Enum\n"
        # For enum files, also import List for helper methods
        code += "from typing import List\n"
    
    # Import types from other files based on actual dependencies
    for dep in sorted(cross_file_deps):
        module, type_name = dep.split(":")
        code += f"from .{module} import {type_name}\n"
    
    if code:
        code += "\n"
    
    return code


def generate_enum(name: str, schema: Dict[str, Any]) -> str:
    """Generate an Enum class."""
    code = f"\nclass {name}(str, Enum):\n"
    
    # Add docstring
    if "description" in schema:
        code += f'    """{schema["description"]}"""\n'
    
    # Add enum values
    for value in schema["enum"]:
        # Convert to valid Python identifier
        attr_name = value.upper().replace("-", "_")
        code += f'    {attr_name} = "{value}"\n'
    
    # Add helper methods for terminal states (special case for EvaluationStatus)
    if name == "EvaluationStatus":
        code += generate_status_helpers()
    
    return code + "\n"


def generate_status_helpers() -> str:
    """Generate helper methods for EvaluationStatus."""
    return '''
    @classmethod
    def terminal_states(cls) -> List["EvaluationStatus"]:
        """Get all terminal states."""
        return [cls.COMPLETED, cls.FAILED, cls.CANCELLED]
    
    def is_terminal(self) -> bool:
        """Check if this is a terminal state."""
        return self in self.terminal_states()
    
    def is_active(self) -> bool:
        """Check if this is an active (non-terminal) state."""
        return not self.is_terminal()
'''


def generate_model(name: str, schema: Dict[str, Any], all_schemas: Dict[str, Any]) -> str:
    """Generate a Pydantic model class."""
    code = f"\nclass {name}(BaseModel):\n"
    
    # Add docstring
    if "description" in schema:
        code += f'    """{schema["description"]}"""\n'
    
    properties = schema.get("properties", {})
    required = schema.get("required", [])
    
    if not properties:
        code += "    pass\n"
        return code
    
    # Generate fields
    for prop_name, prop_def in properties.items():
        field_code = generate_field(prop_name, prop_def, prop_name in required, all_schemas)
        code += f"    {field_code}\n"
    
    return code + "\n"


def generate_field(name: str, schema: Dict[str, Any], is_required: bool, all_schemas: Dict[str, Any]) -> str:
    """Generate a single field definition."""
    # Determine the type
    field_type = determine_field_type(schema, all_schemas)
    
    # Handle optional fields
    is_nullable = schema.get("nullable", False)
    has_default = "default" in schema
    
    if not is_required or is_nullable:
        field_type = f"Optional[{field_type}]"
    
    # Build the field definition  
    if is_required and not has_default and not is_nullable:
        field_def = "Field(...)"
    else:
        default = schema.get("default")
        if default is None or is_nullable:
            field_def = "None"
        elif isinstance(default, str):
            field_def = f'"{default}"'
        elif isinstance(default, bool):
            field_def = str(default)
        elif isinstance(default, (int, float)):
            field_def = str(default)
        elif isinstance(default, dict):
            field_def = "Field(default_factory=dict)"
        elif isinstance(default, list):
            field_def = "Field(default_factory=list)"
        else:
            field_def = repr(default)
    
    # Add Field() wrapper if we have description or other metadata
    if "description" in schema and field_def not in ["...", "None"] and not field_def.startswith("Field"):
        desc = schema["description"].replace('"', '\\"')
        field_def = f'Field({field_def}, description="{desc}")'
    elif "description" in schema and field_def == "...":
        desc = schema["description"].replace('"', '\\"')
        field_def = f'Field(..., description="{desc}")'
    elif "description" in schema and field_def == "None":
        desc = schema["description"].replace('"', '\\"')
        field_def = f'Field(None, description="{desc}")'
    
    return f"{name}: {field_type} = {field_def}"


def determine_field_type(schema: Dict[str, Any], all_schemas: Dict[str, Any]) -> str:
    """Determine the Python type for a field."""
    # Handle $ref
    if "$ref" in schema:
        ref = schema["$ref"]
        
        # Handle cross-file references
        if ref.startswith("./") and "#" in ref:
            # e.g., "./evaluation-status.yaml#/components/schemas/EvaluationStatus"
            type_name = ref.split("/")[-1]
            return type_name
        
        # Handle same-file references
        if ref.startswith("#/"):
            type_name = ref.split("/")[-1]
            if type_name in all_schemas:
                return type_name
        
        # If we can't resolve it, return the type name anyway
        # The import will handle making it available
        return ref.split("/")[-1]
    
    # Handle basic types
    type_map = {
        "string": "str",
        "integer": "int",
        "number": "float",
        "boolean": "bool",
        "array": "List[Any]",  # Should be more specific
        "object": "Dict[str, Any]",
    }
    
    base_type = type_map.get(schema.get("type", ""), "Any")
    
    # Handle arrays with specific item types
    if schema.get("type") == "array" and "items" in schema:
        item_type = determine_field_type(schema["items"], all_schemas)
        base_type = f"List[{item_type}]"
    
    # Handle datetime
    if schema.get("format") == "date-time":
        base_type = "datetime"
    
    return base_type


def generate_event_channels() -> str:
    """Generate event channel constants."""
    return '''
class EventChannels:
    """Redis pub/sub channel names for events."""
    EVALUATION_QUEUED = "evaluation:queued"
    EVALUATION_RUNNING = "evaluation:running"
    EVALUATION_COMPLETED = "evaluation:completed"
    EVALUATION_FAILED = "evaluation:failed"
'''


def update_init_file(output_dir: Path, modules: List[tuple], all_exports: List[str]):
    """Update __init__.py to export all generated types."""
    code = '''"""
Generated Python types from shared contracts.
DO NOT EDIT FILES IN THIS DIRECTORY - They are auto-generated.

Run 'python shared/scripts/generate-python-types.py' to regenerate.
"""

'''
    
    # Generate imports
    for module_name, exports in modules:
        if exports:
            if len(exports) == 1:
                code += f"from .{module_name} import {exports[0]}\n"
            else:
                code += f"from .{module_name} import {', '.join(exports)}\n"
    
    # Generate __all__
    code += "\n__all__ = [\n"
    for export in sorted(all_exports):
        code += f'    "{export}",\n'
    code += "]\n"
    
    init_file = output_dir / "__init__.py"
    init_file.write_text(code)
    print(f"Updated {init_file}")


# Helper functions
def has_datetime_fields(schema: Dict[str, Any]) -> bool:
    """Check if schema has any datetime fields."""
    if isinstance(schema, dict):
        if schema.get("format") == "date-time":
            return True
        for value in schema.values():
            if has_datetime_fields(value):
                return True
    return False


def has_optional_fields(schema: Dict[str, Any]) -> bool:
    """Check if schema has optional fields."""
    properties = schema.get("properties", {})
    required = schema.get("required", [])
    
    for prop_name, prop_def in properties.items():
        if prop_name not in required or prop_def.get("nullable", False):
            return True
    return False


def has_dict_fields(schema: Dict[str, Any]) -> bool:
    """Check if schema has dict/object fields."""
    return any(
        prop.get("type") == "object" or prop.get("additionalProperties") 
        for prop in schema.get("properties", {}).values()
    )


def has_list_fields(schema: Dict[str, Any]) -> bool:
    """Check if schema has array fields."""
    return any(
        prop.get("type") == "array" 
        for prop in schema.get("properties", {}).values()
    )


if __name__ == "__main__":
    main()